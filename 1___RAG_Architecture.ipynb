{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RAG :\n",
        "\n",
        "\n",
        "RAG stands for Retrieval-Augmented Generation. It's a technique in natural language processing that combines retrieval-based methods with generative models.\n",
        "- **Retrieval Phase:** The model first retrieves relevant documents or pieces of information from a large corpus based on the input query. This is often done using techniques like dense retrieval or traditional information retrieval methods.\n",
        "\n",
        "- **Generation Phase:** After retrieving the relevant information, a generative model (such as a Transformer-based model) generates a response or output based on both the input query and the retrieved documents.\n",
        "---\n",
        "##  1. Introduction  : What is RAG ?\n",
        "RAG is Called Retrieval augmented generation , is an architecture used to help LLMs model like gpt-4 , Gemini , Llama 2 , Mistral to provide a better response by using relevant information <br>  \n",
        "or<br>  \n",
        "RAG is a technique that enhances langueges model generation by incorporating external knowledge , this is typically done by retriving relevent information from a large corpus of documents and using that information to inform the generation process.<br>\n",
        "\n",
        "or\n",
        "<br>\n",
        "With RAG , the LLMs is able to leverage knowledge and information that is not\n",
        "neccessary means it is not inside the traning .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kVL0EHGlpC0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why we should use RAG ?**  \n",
        "1. Limited knowledge access\n",
        "2. Lack of Transparency : LLMs struggle to provide transparent or relevent information\n",
        "3. Hallucinations in answers\n",
        "\n",
        "## RAG Architecture  :    \n",
        "1. Ingestion\n",
        "2. Retrieval\n",
        "3. Generation\n"
      ],
      "metadata": {
        "id": "Lz9hM24cw05Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding The ingestion process :     \n",
        "1. **Document:**\n",
        "In the Typical RAG pipeline , we have knowlwdge sources , such as Local  files , CSV , TSV , JSON , PDF , DOCs , wed pages  XML , Databases , CLoud Storage , any Remote Location Etc.\n",
        "2.  **Chunking :**\n",
        "  We collects the data from varius sources , split the data , into the Chunks.\n",
        "   <br>\n",
        "\n",
        "   **Why chunking is required ?**\n",
        "\n",
        "    we can fed the entire document also but why we are just passing the paragraph so here the reason is  \n",
        "    1. LLM will not be overloaded with information and\n",
        "    2. Even it is having some limits in  terms  of tokens\n",
        "    \n",
        "3. **Embedding :**\n",
        "    \n",
        "After chunking we convert it into vector representaion"
      ],
      "metadata": {
        "id": "QA3KGoRPybE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Retrieval process :** <br>\n"
      ],
      "metadata": {
        "id": "l_Dzi0GQ5Bbs"
      }
    }
  ]
}